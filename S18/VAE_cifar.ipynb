{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOb7kYvhmm0f6tPPH3HyCGh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sparten-Ashvinee/ERA/blob/main/S18/VAE_cifar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACor7jhhjElb",
        "outputId": "fdec8ca9-216f-4378-805b-1742d14a9c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/U-NET/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCjCa1AejPwN",
        "outputId": "e251c36f-d7af-4d8f-af1d-f4469099ed74"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/U-NET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVsvttW7jPue",
        "outputId": "4b4f0b50-ac2f-4d50-c590-fc7c41753d1d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " new_pet_data  'UNet from scratch.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch; torch.manual_seed(0)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils\n",
        "import torch.distributions\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200"
      ],
      "metadata": {
        "id": "DLoYltKwpqgu"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "xVy6-n_nUAE_"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dims = 2\n",
        "autoencoder = VariationalAutoencoder(latent_dims).to(device) # GPU\n",
        "\n",
        "data = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.CIFAR10('./cifar10_data',\n",
        "               transform=torchvision.transforms.ToTensor(),\n",
        "               download=True),\n",
        "        batch_size=25,\n",
        "        shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TmaeVHj1H1j",
        "outputId": "1e7ca3e3-70bc-4051-8c90-883086281ecb"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Assigning random labels"
      ],
      "metadata": {
        "id": "7qruv35wCHjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = iter(data)\n",
        "for i in range(1):\n",
        "  img, lab = next(dataset)\n",
        "  idx = torch.randperm(lab.nelement())\n",
        "  lab = lab.view(-1)[idx].view(lab.size())\n",
        "  lab = torch.nn.functional.one_hot(lab, num_classes=10)\n",
        "\n",
        "  dataset_new = torch.utils.data.TensorDataset(img, lab)\n",
        "  data_loader_ = torch.utils.data.DataLoader(dataset_new, batch_size=25, shuffle=True)\n",
        ""
      ],
      "metadata": {
        "id": "imSV28AvBGF6"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMxOGhi8NYUc",
        "outputId": "9db3fb44-8206-414b-ce24-0a3d7a0f7d05"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([25, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(1024, 512)\n",
        "        self.linear2 = nn.Linear(512, latent_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        return self.linear2(x)"
      ],
      "metadata": {
        "id": "2rsX7-Ik0yH3"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(latent_dims, 512)\n",
        "        self.linear2 = nn.Linear(512, 1024)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = F.relu(self.linear1(z))\n",
        "        z = torch.sigmoid(self.linear2(z))\n",
        "        return z.reshape((-1, 1, 32, 32))"
      ],
      "metadata": {
        "id": "WdDSQeim097Z"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VariationalEncoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(VariationalEncoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(1024, 25)\n",
        "        self.linear2 = nn.Linear(512, latent_dims)\n",
        "        self.linear3 = nn.Linear(512, latent_dims)\n",
        "\n",
        "        self.N = torch.distributions.Normal(0, 1)\n",
        "        self.N.loc = self.N.loc.cuda() # hack to get sampling on the GPU\n",
        "        self.N.scale = self.N.scale.cuda()\n",
        "        self.kl = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        mu =  self.linear2(x)\n",
        "        sigma = torch.exp(self.linear3(x))\n",
        "        z = mu + sigma*self.N.sample(mu.shape)\n",
        "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
        "        return z"
      ],
      "metadata": {
        "id": "RqaWR-D_1E24"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.encoder = VariationalEncoder(latent_dims)\n",
        "        self.decoder = Decoder(latent_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)"
      ],
      "metadata": {
        "id": "VqYSuaY01E0T"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(x, x_hat, mean, log_var):\n",
        "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
        "    KLD      = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
        "    return reproduction_loss + KLD"
      ],
      "metadata": {
        "id": "TqIccBBP1ExD"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(autoencoder, data, epochs=20):\n",
        "    opt = torch.optim.Adam(autoencoder.parameters())\n",
        "    for epoch in range(epochs):\n",
        "        for x, y in data:\n",
        "            x = x.to(device) # GPU\n",
        "            opt.zero_grad()\n",
        "            x_hat = autoencoder(x)\n",
        "            loss = ((x - x_hat)**2).sum()\n",
        "            #loss = torch.nn.KLDivLoss(size_average=False)(F.log_softmax(x, -1), x_hat)\n",
        "            print('Training loss for epoch: ', epoch)\n",
        "            print('Loss: ', loss)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "kVgEhzSw1AFa"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VariationalAutoencoder(latent_dims).to(device) # GPU"
      ],
      "metadata": {
        "id": "YfKdEWH8F4Ve"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = train(vae, data_loader_, epochs=10)"
      ],
      "metadata": {
        "id": "GsKeJY51-lOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_reconstructed(autoencoder, r0=(-5, 10), r1=(-10, 5), n=5):\n",
        "    w = 32\n",
        "    img = np.zeros((n*w, n*w))\n",
        "    for i, y in enumerate(np.linspace(*r1, n)):\n",
        "        for j, x in enumerate(np.linspace(*r0, n)):\n",
        "            z = torch.Tensor([[x, y]]).to(device)\n",
        "            x_hat = autoencoder.decoder(z)\n",
        "            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()\n",
        "            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat\n",
        "    plt.imshow(img, extent=[*r0, *r1])"
      ],
      "metadata": {
        "id": "cwEs8HOJ1Hyo"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_reconstructed(vae, r0=(-3, 3), r1=(-3, 3))"
      ],
      "metadata": {
        "id": "8kXrYBs71Hvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJDg8GAXQjpZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}